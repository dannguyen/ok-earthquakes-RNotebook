---
title: "Chapter 4: Geolocation data"
author: "Dan Nguyen"
date: "August 17, 2015"
output:
  md_document:
    variant: markdown_github
---

Questions to answer:
- What are the geospatial characteristics of the recent Earthquakes?
- Is the recent spurt of earthquakes located in one area?
- What is the correlation between well activity and earthquakes?


## Setup


- [readxl](https://github.com/hadley/readxl) - Later on we'll need to read from an XLS file. Again, via Hadley Wickham.



```{r, message = FALSE}
# Load libraries
library(ggplot2)
require(grid)
library(dplyr)
library(lubridate)
library(rgdal)
library(readxl)

# load my themes:
source("./myslimthemes.R")
theme_set(theme_dan())

# create a data directory
dir.create('./data')

```

Download the map data as before:

```{r, message = F}
fname <- "./data/cb_2014_us_state_20m.zip"
if (!file.exists(fname)){
  url <- "http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_state_20m.zip"
  print(paste("Downloading: ", url))
  download.file(url, fname)
}
unzip(fname, exdir = "./data/shp")
#
# Read the map data
us_map <- readOGR("./data/shp/cb_2014_us_state_20m.shp", "cb_2014_us_state_20m")
states_map <- us_map[!us_map$STUSPS %in%
                        c('AS', 'DC', 'GU', 'MP', 'PR', 'VI'),]

# For mapping purposes, we'll make a contiguous-states only
cg_map <- states_map[!states_map$STUSPS %in% c('AK', 'HI'), ]
# And for Oklahoma
ok_map <- states_map[states_map$STUSPS == 'OK', ]

```


Download the quakes data as before:


```{r, message = F}
fn <- './data/usgs-quakes-dump.csv'
zname <- paste(fn, 'zip', sep = '.')
if (!file.exists(zname) || file.size(zname) < 2048){
  url <- paste("https://github.com/dannguyen/ok-earthquakes-RNotebook",
    "raw/master/data", zname, sep = '/')
  print(paste("Downloading: ", url))
  # note: if you have problems downloading from https, you might need to include
  # RCurl
  download.file(url, zname, method = "libcurl")
}
unzip(zname, exdir="data")
# read the data into a dataframe
usgs_data <- read.csv(fn, stringsAsFactors = FALSE)

# Remove all non earthquakes and events with magnitude less than 3.0:
quakes <- usgs_data %>% filter(mag >= 3.0) %>%
  filter(type == 'earthquake')

quakes$year <- year(quakes$time)
quakes$year_month <- strftime(quakes$time, "%Y-%m")
quakes <- mutate(quakes, era = ifelse(year <= 2000, "1995-2000",
          ifelse(year <= 2005, "2001-2005",
          ifelse(year <= 2010, "2006-2010", "2011-2015"))))

# Create a spatial data frame----------------------------------
sp_quakes <- SpatialPointsDataFrame(data = quakes,
                          coords = quakes[,c("longitude", "latitude")])
sp_quakes@proj4string <- states_map@proj4string

# subset for earthquakes in the U.S.
xdf <- over(sp_quakes, states_map[, 'STUSPS'])
states_quakes <- cbind(sp_quakes, xdf) %>% filter(!is.na(STUSPS))

# And for convenience, OK-only
ok_quakes <- filter(states_quakes, STUSPS == 'OK')
```











## Injection volumes

Download # http://www.occeweb.com/og/ogdatafiles2.htm

2011:

```{r, message = F}
fname <- "./data/2011_UIC_Injection_Volumes_Report.xlsx"
if (!file.exists(fname)){
  url <- "http://www.occeweb.com/og/2011INJECTIONVOLUMES.xlsx"
  print(paste("Downloading: ", url))
  download.file(url, fname)
}
tdf <- read_excel(fname)
# remove NA columns http://stackoverflow.com/questions/15968494/how-to-delete-columns-with-na-in-r
injections_data.2011 <- tdf[, colSums(is.na(tdf)) != nrow(tdf)] %>%
    mutate(Volume = as.integer(Volume))

sum(injections_data.2011$Volume)
```

2012:

```{r, message = F}
fname <- "./data/2012_UIC_Injection_Volumes_Report.xlsx"
if (!file.exists(fname)){
  url <- "http://www.occeweb.com/og/2012Injections20141029.xlsx"
  print(paste("Downloading: ", url))
  download.file(url, fname)
}
tdf  <- read_excel(fname)
injections_data.2012 <- tdf[, colSums(is.na(tdf)) != nrow(tdf)] %>%
    mutate(Volume = as.numeric(Volume)) %>%
    filter(!is.na(Volume))
sum(injections_data.2012$Volume)
```


2013:

```{r, message = F}
fname <- "./data/2013_UIC_Injection_Volumes_Report.xlsx"
if (!file.exists(fname)){
  url <- "http://www.occeweb.com/og/2013%20UIC%20Injection%20Volumes%20Report.xlsx"
  print(paste("Downloading: ", url))
  download.file(url, fname)
}
injections_data_2013 <- read_excel(fname)
injections_2013 <-  injections_data_2013 %>%
    mutate(Volume = as.numeric(Volume),
           API = as.character(API)) %>% 
    # filter out rows with missing Volume or erroneous X/Y
    filter(!is.na(Volume),
           !is.na(X), X != 0,  X < -90, X > -100,
           !is.na(Y), Y != 0, Y > 33.5, Y < 40)
```


Aggregate the wells by their unique identifier and create a `total_volume` column:


```{r}
wells_2013 <-  as.data.frame(group_by(injections_2013, API) %>%
    summarise(counts = n(), total_volume = sum(Volume)) %>%
    arrange(desc(counts)))
```




-------------
Map it:

```{r}
ggplot() +
  geom_polygon(data = ok_map, aes(x = long, y = lat, group = group),
               fill = "white", color = "black") +
  geom_point(data = filter(wells_2013, total_volume < 1250000),
             aes(x = X, y = Y),
             alpha = 0.1 , color = 'yellow') +
  geom_point(data = filter(wells_2013, total_volume > 1250000),
             aes(x = X, y = Y),
             alpha = 0.1 , color = 'purple') +
  geom_point(data = ok_quakes, aes(x = longitude, y = latitude),
            alpha = 0.1, size = 0.3, shape = 1, color = 'red') +
  coord_map("albers", lat0 = 38, latl = 42) + theme_dan_map()
```



## Maps


TK: Justify the use of Hexbin map, similar to binning by year instead of day


Hexbin map without projection

```{r}
ggplot() +
  geom_polygon(data = ok_map, aes(x = long, y = lat, group = group),
               fill = "white", color = "black") +
  stat_binhex(data = ok_quakes, aes(x = longitude, y = latitude, alpha = ..count..), bins = 20 ) + 
  coord_equal() + 
  theme_dan_map()
```



TK: http://stackoverflow.com/questions/13167531/ggplot2-multiple-stat-binhex-plots-with-different-color-gradients-in-one-image


Hexbin map with injections
```{r}
ggplot() +
  geom_polygon(data = ok_map, aes(x = long, y = lat, group = group),
               fill = "white", color = "black") +
  stat_summary_hex(data = wells_2013, aes(x = X, y = Y, z = total_volume), alpha = 0.9, bins = 20 ) + 
  geom_point(data = ok_quakes, aes(x = longitude, y = latitude),
           alpha = 0.1, size = 0.2, shape = 1, color = 'red')

```




-------------


```{r}

sp_ok_quakes <- SpatialPointsDataFrame(data = ok_quakes,
                          coords = ok_quakes[,c("longitude", "latitude")])
proj4string(sp_ok_quakes) <- proj4string(ok_map)

sp_injections <- SpatialPointsDataFrame(data = injections,
                          coords = injections[,c("X", "Y")])

proj4string(sp_injections) <- proj4string(ok_map)

albers_crs <- CRS("+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +a=6370997 +b=6370997 +units=m +no_defs")
ok_map.albers <- spTransform(ok_map, albers_crs)
ok_quakes.albers <- as.data.frame(spTransform(sp_ok_quakes, albers_crs))
injections.albers <- as.data.frame(spTransform(sp_injections, albers_crs))

###0-----------
# look ma, no coord_map
ggplot() +
  geom_polygon(data = ok_map.albers, aes(x = long, y = lat, group = group),
               fill = "white", color = "black") +
  geom_point(data = filter(injections.albers, total_volume > 100000),
             aes(x = X, y = Y),
             alpha = 0.1 , color = 'yellow') +

  geom_point(data = ok_quakes.albers, aes(x = longitude, y = latitude),
            alpha = 0.1, size = 0.2, shape = 1, color = 'red')
```





<!--
To render this file:
library(rmarkdown)
setwd("~/Dropbox/rprojs/ok-earthquakes-Rnotebook/")

this_file <- 'chapter-4-geocorrelation.Rmd'
render(this_file, output_dir = './builds',
  html_document(toc = TRUE, self_contained = F))

render(this_file, output_dir = './builds',
  md_document(variant = "markdown_github",
              preserve_yaml = TRUE))
-->


The study, titled "Oklahoma's Recent Earthquakes and Saltwater Disposal," was funded by the Stanford Center for Induced and Triggered Seismicity, an affiliate program at the School of Earth, Energy & Environmental Sciences.


> Active faults in Oklahoma might trigger an earthquake every few thousand years. However, by increasing the fluid pressure through disposal of wastewater into the Arbuckle formation in the three areas of concentrated seismicity – from about 20 million barrels per year in 1997 to about 400 million barrels per year in 2013 – humans have sped up this process dramatically. "The earthquakes in Oklahoma would have happened eventually," Walsh said. "But by injecting water into the faults and pressurizing them, we've advanced the clock and made them occur today."



http://news.stanford.edu/news/2015/june/okla-quake-drilling-061815.html
