---
title: "Part 2: Basic R Concepts"
author: "Dan Nguyen"
date: "August 17, 2015"
output:
  md_document:
    variant: markdown_github
---

## Loading the libraries

```{r, message = FALSE}
library(dplyr)
library(lubridate)
library(rgdal)
library(ggplot2)
require(grid)
```

- [ggplot2](http://ggplot2.org/) is _the_ visualization framework. Made by Hadley Wickham.
- [dplyr](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html), also made by Hadley Wickham, is a library for manipulating dataframes and includes transformations such as `mutate()` and `filter()` as well as aggregation functions. It also has [nice piping](http://seananderson.ca/2014/09/13/dplyr-intro.html), which warms the Unix programmer inside me.
- [lubridate](https://github.com/hadley/lubridate) - I include Wickham's time-handling library only for its convenience functions, such as [year()](https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html), which seems like overkill if you've never dealt with trying to parse time values as a programmer. Think of it as [moment.js for R](http://momentjs.com/).
- [grid](https://stat.ethz.ch/R-manual/R-devel/library/grid/html/grid-package.html) - contains some functionality that ggplot2 uses for chart styling, particularly the [unit()](https://stat.ethz.ch/R-manual/R-devel/library/grid/html/unit.html) function.
- [rgdal](https://cran.r-project.org/web/packages/rgdal/index.html) - bindings for geospatial operations, including map projection and the reading of map shapefiles. Can be a bear to install due to a variety of dependencies. If you're on OS X, I recommend [installing Homebrew](http://brew.sh/) and running `brew install gdal` before installing the rgdal package via R.


## Downloading the data

There are two data files we need:

- __[A feed of earthquake reports in CSV format from the U.S. Geological Survey](http://earthquake.usgs.gov/earthquakes/feed/v1.0/csv.php).__ For this section, we'll start by using the ["Past 30 Days - All Earthquakes"](http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv) feed, which can be downloaded at this URL:

    http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv

- __[Cartographic boundary shapefiles for U.S. state boundaries, via the U.S. Census](https://www.census.gov/geo/maps-data/data/tiger-cart-boundary.html)__. The listing of state boundaries can be [found here](https://www.census.gov/geo/maps-data/data/cbf/cbf_state.html). There are several levels of detail; the resolution of `1:5,000,000` is good enough for our purposes:

    http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_state_5m.zip


If you're following along many years from now and the above links no longer work, the [Github repo for this walkthrough](https://github.com/dannguyen/ok-earthquakes-RNotebook) contains copies of the raw files for you to practice on. You can either just clone this repo to get the files. Or download them here (these URLs are subject to the whims of Github's framework and may change down the road):

- [https://raw.githubusercontent.com/dannguyen/ok-earthquakes-RNotebook/master/data/all_month.csv](https://raw.githubusercontent.com/dannguyen/ok-earthquakes-RNotebook/master/data/all_month.csv)
- [https://raw.githubusercontent.com/dannguyen/ok-earthquakes-RNotebook/master/data/cb_2014_us_state_5m.zip](https://raw.githubusercontent.com/dannguyen/ok-earthquakes-RNotebook/master/data/cb_2014_us_state_5m.zip)



First we create a data directory to store our files:

```{r}
dir.create('./data')
```


### Download earthquake data into a data frame

```{r, message = FALSE}
url <- "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/all_month.csv"
fname <- "./data/all_month.csv"
if (!file.exists(fname)) download.file(url, fname)
```

The standard __read.csv()__ function can be used to convert the CSV file into a data frame, which I store into a variable named `usgs_data`:

```{r}
usgs_data <- read.csv(fname, stringsAsFactors = FALSE)
```



### Download and read the map data

```{r, message = FALSE}
url <- "http://www2.census.gov/geo/tiger/GENZ2014/shp/cb_2014_us_state_5m.zip"
fname <- "./data/cb_2014_us_state_5m.zip"
if (!file.exists(fname)) download.file(url, fname)
unzip(fname, exdir = "./data/shp")
```

Inside the `data/` directory should be a subdirectory named `shp/` with a variety of data files. Using the __rgdal__ library, this is how we read in the boundary data and assign it to the variable `us_map`:

```{r, message = FALSE}
us_map <- readOGR("./data/shp/cb_2014_us_state_5m.shp", "cb_2014_us_state_5m")
```



